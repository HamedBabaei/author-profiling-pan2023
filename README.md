# Leveraging Large Language Models with Multiple Loss Learners for Few-Shot Author Profiling
*Hamed Babaei Giglou, Mostafa Rahgouy, Jennifer Dâ€™Souza, Milad Molazadeh Oskuee , Hadi Bayrami Asl Tekanlou and Cheryl D Seals*

![File](images/main-diagram.png)

**Abstract**: The objective of author profiling (AP) is to study the characteristics of authors through the analysis of how language is exchanged among people. Studying these attributes sometimes is challenging due to the lack of annotated data. This indicates the significance of studying AP from a low-resource perspective. This year at AP@PAN 2023 the major interest raised in profiling cryptocurrency influencers with a few-shot learning technique to analyze the effectiveness of advanced approaches in dealing with new tasks from a low-resource perspective. The AP-2023 task consists of 3 subtasks including cryptocurrency influencer analysis, interest identification, and intent identification.  In this work, we studied the integration of Bi-Encoders with Large Language Models (LLMs), to enhance the semantic representation of authors by enabling the models to transfer knowledge across domains and adapt to new tasks with a small number of data. We incorporated multi-losses to enforce LLMs to learn the representations of different categories and authors to facilitate similarity-based comparisons among authors and categories. Finally, our approach achieved impressive F1 Macro scores of $52.31$ for crypto influencer profiling, $61.21$ for crypto influencer interest identification, and $65.83$ for crypto influencer intent identification using limited supervised learning data.  Overall, the obtained and experimental analysis shows the effectiveness of the integration of multiple-loss learners with LLMs in profiling cryptocurrency influencers using limited resources.


## Cite us as:

```bib


```


